{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39757ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd8a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature Engineering Complete! Tensors saved in /data/\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# FIFA World Cup Goals - Feature Engineering\n",
    "# ===========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# ============================\n",
    "# 1. LOAD CSV WITH CORRECT ENCODING\n",
    "# ============================\n",
    "df = pd.read_csv(\n",
    "    \"data/FIFA World Cup All Goals 1930-2022.csv\",\n",
    "    encoding='latin1'  # solves UnicodeDecodeError\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2. RENAME COLUMNS AND CREATE SCORER\n",
    "# ============================\n",
    "df.rename(columns={\n",
    "    'team_name': 'Team',\n",
    "    'minute_label': 'Minute',\n",
    "    'family_name': 'FamilyName',\n",
    "    'given_name': 'GivenName'\n",
    "}, inplace=True)\n",
    "\n",
    "# Combine first + last name\n",
    "df['Scorer'] = df['GivenName'].astype(str) + ' ' + df['FamilyName'].astype(str)\n",
    "\n",
    "# ============================\n",
    "# 3. EXTRACT NUMERIC MINUTE\n",
    "# ============================\n",
    "def extract_minute(m):\n",
    "    if isinstance(m, str):\n",
    "        m = m.replace(\"'\", \"\")  # remove apostrophe\n",
    "        if \"+\" in m:\n",
    "            parts = m.split(\"+\")\n",
    "            return int(parts[0]) + int(parts[1])\n",
    "        else:\n",
    "            return int(m)\n",
    "    return int(m)\n",
    "\n",
    "df['Minute'] = df['Minute'].apply(extract_minute)\n",
    "\n",
    "# Drop rows missing essential info\n",
    "df = df.dropna(subset=['Scorer', 'Team', 'Minute'])\n",
    "\n",
    "# ============================\n",
    "# 4. FEATURE ENGINEERING\n",
    "# ============================\n",
    "\n",
    "# Minute category\n",
    "def minute_category(m):\n",
    "    if m <= 15: return \"Early\"\n",
    "    elif m <= 45: return \"MidFirst\"\n",
    "    elif m <= 60: return \"EarlySecond\"\n",
    "    elif m <= 75: return \"MidSecond\"\n",
    "    else: return \"Late\"\n",
    "\n",
    "df['MinuteCat'] = df['Minute'].apply(minute_category)\n",
    "\n",
    "# Team Strength Proxy: normalize team goals\n",
    "team_strength = df['Team'].value_counts() / df['Team'].value_counts().max()\n",
    "df['TeamStrength'] = df['Team'].map(team_strength)\n",
    "\n",
    "# Encode categorical features\n",
    "cat_features = ['Team', 'Scorer', 'MinuteCat']\n",
    "encoders = {}\n",
    "for col in cat_features:\n",
    "    enc = LabelEncoder()\n",
    "    df[col] = enc.fit_transform(df[col])\n",
    "    encoders[col] = enc\n",
    "\n",
    "# ============================\n",
    "# 5. FINAL FEATURE MATRIX\n",
    "# ============================\n",
    "feature_cols = ['Minute', 'MinuteCat', 'Team', 'Scorer', 'TeamStrength']\n",
    "X = df[feature_cols].values\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Target placeholder (all goals = 1)\n",
    "y = np.ones(len(df))\n",
    "\n",
    "# ============================\n",
    "# 6. TRAIN-TEST SPLIT\n",
    "# ============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 7. SAVE AS PYTORCH TENSORS\n",
    "# ============================\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor  = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor  = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "torch.save(X_train_tensor, \"data/X_train.pt\")\n",
    "torch.save(X_test_tensor,  \"data/X_test.pt\")\n",
    "torch.save(y_train_tensor, \"data/y_train.pt\")\n",
    "torch.save(y_test_tensor,  \"data/y_test.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a05597",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 814: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# FIFA World Cup Goal Prediction with EM Clustering + PyTorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Example dataset: FIFA World Cup Shot Events (StatsBomb or Kaggle)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/FIFA World Cup All Goals 1930-2022.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Core numeric features\u001b[39;00m\n\u001b[32m     11\u001b[39m numeric_features = [\u001b[33m'\u001b[39m\u001b[33mshot_distance\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mshot_angle\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:574\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:663\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._get_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xe9 in position 814: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# FIFA World Cup Goal Prediction with EM Clustering + PyTorch\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load & Preprocess Data\n",
    "# ---------------------------\n",
    "# Example dataset: FIFA World Cup Shot Events (StatsBomb or Kaggle)\n",
    "data = pd.read_csv(\"data/FIFA World Cup All Goals 1930-2022.csv\")\n",
    "\n",
    "# Core numeric features\n",
    "numeric_features = ['shot_distance', 'shot_angle']\n",
    "\n",
    "# Optional defensive context (only if dataset has it)\n",
    "extra_features = ['pressure', 'player_position']  # remove if not available\n",
    "available_extras = [f for f in extra_features if f in data.columns]\n",
    "numeric_features += available_extras\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['shot_type', 'body_part', 'player']\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in data.columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Final features for EM + NN\n",
    "features_for_nn = numeric_features + categorical_features\n",
    "X = data[features_for_nn].values\n",
    "y = data['goal'].values\n",
    "\n",
    "# Standardize numeric data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. EM Clustering (Shot Types)\n",
    "# ---------------------------\n",
    "n_clusters = 5  # latent shot categories (tweak if needed)\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "cluster_labels = gmm.fit_predict(X_scaled)\n",
    "\n",
    "data['shot_cluster'] = cluster_labels\n",
    "X_final = np.hstack([X_scaled, cluster_labels.reshape(-1,1)])\n",
    "features_for_nn.append('shot_cluster')\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Train/Test Split\n",
    "# ---------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "y_test  = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. PyTorch Model\n",
    "# ---------------------------\n",
    "class GoalPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 32), nn.ReLU(),\n",
    "            nn.Linear(32, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = GoalPredictor(X_train.shape[1])\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Train Model\n",
    "# ---------------------------\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 60\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "plt.plot(losses); plt.title(\"Training Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Evaluate Model\n",
    "# ---------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_prob = model(X_test)\n",
    "    y_pred = (y_prob >= 0.5).float()\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Visualize Shot Clusters\n",
    "# ---------------------------\n",
    "plt.scatter(data['shot_angle'], data['shot_distance'], \n",
    "            c=data['shot_cluster'], cmap='viridis', alpha=0.6)\n",
    "plt.xlabel(\"Shot Angle (degrees)\")\n",
    "plt.ylabel(\"Shot Distance (meters)\")\n",
    "plt.title(\"EM Clusters of World Cup Shots\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
